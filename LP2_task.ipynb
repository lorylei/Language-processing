{"cells":[{"cell_type":"code","execution_count":null,"id":"4a1e126d","metadata":{"id":"4a1e126d"},"outputs":[],"source":["import os\n","import pandas as pd\n","import numpy as np\n","from xml.dom import minidom\n","import xml.etree.ElementTree as ET\n","from nltk.tokenize import WordPunctTokenizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.svm import SVC\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.metrics import accuracy_score\n","import gensim.downloader as api\n","import torch\n","import torch.nn as nn\n","import torch.utils.data as Data"]},{"cell_type":"code","execution_count":null,"id":"6d5cd56d","metadata":{"id":"6d5cd56d"},"outputs":[],"source":["#file list\n","path = './pan22-author-profiling-training-2022-03-29/en/'\n","f_list = os.listdir(path)\n","file_list = []\n","for f in f_list:\n","    if f == 'truth.txt':\n","        pass\n","    else:\n","        file_list.append(f)"]},{"cell_type":"code","execution_count":null,"id":"c56c39eb","metadata":{"id":"c56c39eb"},"outputs":[],"source":["# extracting labels \n","info_file = path+'truth.txt'\n","labels = np.zeros((420,2),dtype = list)\n","with open(info_file) as f:\n","  i = 0\n","  for line in f:\n","    l = line.split(':::')\n","    labels[i,0] = l[0]\n","    labels[i,1] = l[1][:-1]\n","    i+=1\n","    \n","\n","labels_df = pd.DataFrame(labels, columns = ['name','is'])"]},{"cell_type":"code","execution_count":null,"id":"c3dfb3cf","metadata":{"id":"c3dfb3cf"},"outputs":[],"source":["model = api.load('glove-twitter-100')\n","tokenizer = WordPunctTokenizer()"]},{"cell_type":"code","execution_count":null,"id":"a6e2f1c0","metadata":{"id":"a6e2f1c0"},"outputs":[],"source":["#method 1 - vector containing average embedding from each tweet\n","tweets = np.zeros((len(file_list),201), dtype = float)\n","for f in range(len(file_list)):\n","    tree = ET.parse(path+file_list[f])\n","    root = tree.getroot()\n","    \n","    if labels[f,1] == 'NI':\n","        tweets[f,0] = 0\n","    else:\n","        tweets[f,0] = 1\n","        \n","    for i in range(len(root[0])):\n","        v= []\n","        tweet = (root[0][i].text).lower()\n","        tokens = ([tweet.lower() for tweet in tokenizer.tokenize(tweet)])\n","        for t in tokens:\n","            if t in model.key_to_index.keys():\n","                vec = model.get_vector(t)\n","                tweets[f,i+1] = np.mean(vec)"]},{"cell_type":"code","execution_count":null,"id":"bba4480b","metadata":{"id":"bba4480b"},"outputs":[],"source":["df = pd.DataFrame(tweets)\n","display(df)"]},{"cell_type":"code","execution_count":null,"id":"7457d5c1","metadata":{"id":"7457d5c1"},"outputs":[],"source":["#splitting the dataset into training and test set\n","train, test = train_test_split(df, test_size=60)"]},{"cell_type":"code","execution_count":null,"id":"0d382a82","metadata":{"id":"0d382a82"},"outputs":[],"source":["#extracting values and labels\n","x_train = train.loc[:,1:].values\n","y_train = train[0].values\n","x_test = test.loc[:,1:].values\n","y_test = test[0].values\n","\n","#array for one user\n","x_train = np.asarray(x_train)"]},{"cell_type":"code","execution_count":null,"id":"062b1f23","metadata":{"id":"062b1f23"},"outputs":[],"source":["# simple classifiers\n","\n","#accuracy for test set\n","clf = SVC(kernel='linear', probability=True)\n","clf.fit(x_train,list(y_train))\n","pre1 = clf.predict(x_test)\n","acc = accuracy_score(y_test, pre1)\n","print(acc)\n","\n","clf =  MLPClassifier(alpha=1,max_iter=1000)\n","clf.fit(x_train, y_train)\n","pre1 = clf.predict(x_test)\n","acc = accuracy_score(y_test, pre1)\n","print(acc)\n","\n","clf =  GaussianNB()\n","clf.fit(x_train, y_train)\n","pre1 = clf.predict(x_test)\n","acc = accuracy_score(y_test, pre1)\n","print(acc)"]},{"cell_type":"code","execution_count":null,"id":"79b18b5b","metadata":{"id":"79b18b5b"},"outputs":[],"source":["#accuracy for training set\n","clf = SVC(kernel='linear', probability=True)\n","clf.fit(x_train,list(y_train))\n","pre1 = clf.predict(x_train)\n","acc = accuracy_score(y_train, pre1)\n","print(acc)\n","\n","clf =  MLPClassifier(alpha=1,max_iter=1000)\n","clf.fit(x_train, y_train)\n","pre1 = clf.predict(x_train)\n","acc = accuracy_score(y_train, pre1)\n","print(acc)\n","\n","clf =  GaussianNB()\n","clf.fit(x_train, y_train)\n","pre1 = clf.predict(x_train)\n","acc = accuracy_score(y_train, pre1)\n","print(acc)"]},{"cell_type":"code","execution_count":null,"id":"ca9f0277","metadata":{"id":"ca9f0277"},"outputs":[],"source":["#LSTM model\n","\n","input_size = 200\n","\n","class LSTM(nn.Module):\n","    def __init__(self, input_size=input_size, hidden_layer_size=100, output_size=1):\n","       \n","        super().__init__()\n","        self.hidden_layer_size = hidden_layer_size\n","        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n","        self.linear = nn.Linear(hidden_layer_size, output_size)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, input_x):\n","        input_x = input_x.view(len(input_x), 1, -1)\n","        hidden_cell = (torch.zeros(1, 1, self.hidden_layer_size),  # shape: (n_layers, batch, hidden_size)\n","                       torch.zeros(1, 1, self.hidden_layer_size))\n","        lstm_out, (h_n, h_c) = self.lstm(input_x, hidden_cell)\n","        linear_out = self.linear(lstm_out.view(len(input_x), -1))  # =self.linear(lstm_out[:, -1, :])\n","        predictions = self.sigmoid(linear_out)\n","        return predictions"]},{"cell_type":"code","execution_count":null,"id":"da86196a","metadata":{"id":"da86196a"},"outputs":[],"source":["x, y = torch.from_numpy(x_train.astype(float)).to(torch.float32), torch.from_numpy(np.array(y_train)).to(torch.float32)\n","\n","train_loader = Data.DataLoader(\n","        dataset=Data.TensorDataset(x, y), \n","        batch_size=1,  \n","        shuffle=True,  \n","        num_workers=2, \n","    )\n","lstm = LSTM()  \n","loss_function = nn.BCELoss()  # loss\n","optimizer = torch.optim.Adam(lstm.parameters(), lr=0.001)  \n","epochs = 10\n","    \n","lstm.train()\n","for i in range(epochs):\n","    for seq, labels in train_loader:\n","        optimizer.zero_grad()\n","        y_pred = lstm(seq).squeeze()  \n","        labels = labels.squeeze()\n","        single_loss = loss_function(y_pred, labels)\n","           \n","        single_loss.backward()\n","        optimizer.step()\n","       \n","lstm.eval()\n","\n","for seq, labels in train_loader:  \n","    y_pred = lstm(seq).squeeze()  \n","    labels = labels.squeeze()\n","    single_loss = loss_function(y_pred, labels)\n","    print(y_pred)\n","\n"]},{"cell_type":"code","execution_count":null,"id":"897da63f","metadata":{"id":"897da63f"},"outputs":[],"source":["x = torch.from_numpy(np.array(x_test))\n","y_test_pred = lstm(x.float())\n","\n","y_test_pred = y_test_pred.cpu().detach().numpy()\n","\n","result = []\n","for i in y_test_pred:\n","    if i >0.5:\n","        result.append(1)\n","    else:\n","        result.append(0)\n","        \n"," \n","#accuracy for LSTM classification\n","result = np.array(result).squeeze()\n","acc = accuracy_score(result.astype(int),y_test.astype(int))\n","print(acc)"]},{"cell_type":"code","execution_count":null,"id":"524b09be","metadata":{"id":"524b09be"},"outputs":[],"source":["# Pre--processing method 2\n","def get_phrase_embedding(phrase):\n","\n","    vector = np.zeros([model.vector_size], dtype='float32')\n","    \n","    phrase = phrase.lower()\n","    phrase = tokenizer.tokenize(phrase)\n","    \n","    phrase_vectors = []\n","    \n","    for i in phrase:\n","        if i in model.key_to_index.keys():\n","            phrase_vectors.append(model.get_vector(i))\n","    \n","    phrase_vectors = np.array(phrase_vectors)\n","    \n","    if len(phrase_vectors) == 0:\n","        return vector\n","    \n","    phrase_vectors = np.mean(phrase_vectors, axis=0)\n","    \n","    return phrase_vectors\n","\n","def get_person_vector(phrase):\n","    data = []\n","    N = len(phrase[0])\n","    for n in range(0,N):\n","        vector = get_phrase_embedding(str(phrase[0][n].text))\n","        data.append(vector)\n","    data1 = np.array(data).reshape(20000,)\n","    return data1"]},{"cell_type":"code","execution_count":null,"id":"d67fec2a","metadata":{"id":"d67fec2a"},"outputs":[],"source":["data = []\n","\n","for f in range(len(file_list)): \n","    file = file_list[f]\n","    tree = ET.parse(path+\"/\"+file)\n","    root = tree.getroot()\n","    vector = get_person_vector(root)\n","    is_is = labels_df['is'][f]\n","    if is_is =='I':\n","        data.append([vector,0])\n","    else:\n","        data.append([vector,1])"]},{"cell_type":"code","execution_count":null,"id":"702c996b","metadata":{"id":"702c996b"},"outputs":[],"source":["df = pd.DataFrame(data) \n","display(df)"]},{"cell_type":"code","execution_count":null,"id":"d31c17cc","metadata":{"id":"d31c17cc"},"outputs":[],"source":["train, test = train_test_split(df, test_size=60)\n","x_train = list(train[0].values)\n","x_test = list(test[0].values)\n","y_train = train[1].values\n","y_test = test[1].values"]},{"cell_type":"code","execution_count":null,"id":"dc97b089","metadata":{"id":"dc97b089"},"outputs":[],"source":["# simple classifiers\n","\n","#accuracy for test set\n","clf = SVC(kernel='linear', probability=True)\n","clf.fit(x_train,list(y_train))\n","pre1 = clf.predict(x_test)\n","acc = accuracy_score(y_test, pre1)\n","print(acc)\n","\n","clf =  MLPClassifier(alpha=1,max_iter=1000)\n","clf.fit(x_train, y_train)\n","pre1 = clf.predict(x_test)\n","acc = accuracy_score(y_test, pre1)\n","print(acc)\n","\n","clf =  GaussianNB()\n","clf.fit(x_train, y_train)\n","pre1 = clf.predict(x_test)\n","acc = accuracy_score(y_test, pre1)\n","print(acc)"]},{"cell_type":"code","execution_count":null,"id":"be846858","metadata":{"id":"be846858"},"outputs":[],"source":["#accuracy for training set\n","clf = SVC(kernel='linear', probability=True)\n","clf.fit(x_train,list(y_train))\n","pre1 = clf.predict(x_train)\n","acc = accuracy_score(y_train, pre1)\n","print(acc)\n","\n","clf =  MLPClassifier(alpha=1,max_iter=1000)\n","clf.fit(x_train, y_train)\n","pre1 = clf.predict(x_train)\n","acc = accuracy_score(y_train, pre1)\n","print(acc)\n","\n","clf =  GaussianNB()\n","clf.fit(x_train, y_train)\n","pre1 = clf.predict(x_train)\n","acc = accuracy_score(y_train, pre1)\n","print(acc)"]},{"cell_type":"code","execution_count":null,"id":"cd53b8b7","metadata":{"id":"cd53b8b7"},"outputs":[],"source":["#LSTM\n","\n","class LSTM(nn.Module):\n","    def __init__(self, input_size=20000, hidden_layer_size=100, output_size=1):\n","       \n","        super().__init__()\n","        self.hidden_layer_size = hidden_layer_size\n","        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n","        self.linear = nn.Linear(hidden_layer_size, output_size)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, input_x):\n","        input_x = input_x.view(len(input_x), 1, -1)\n","        hidden_cell = (torch.zeros(1, 1, self.hidden_layer_size),  # shape: (n_layers, batch, hidden_size)\n","                       torch.zeros(1, 1, self.hidden_layer_size))\n","        lstm_out, (h_n, h_c) = self.lstm(input_x, hidden_cell)\n","        linear_out = self.linear(lstm_out.view(len(input_x), -1))  # =self.linear(lstm_out[:, -1, :])\n","        predictions = self.sigmoid(linear_out)\n","        return predictions"]},{"cell_type":"code","execution_count":null,"id":"556ebe73","metadata":{"id":"556ebe73"},"outputs":[],"source":["a = np.ones((420,200,100))\n","b = df[0].values\n","for i in range(420):\n","    a[i]=b[i].reshape(200,100)\n","\n","x, y = torch.from_numpy(a.astype(float)).to(torch.float32), torch.from_numpy(np.array(df[1].values)).to(torch.float32)\n","\n","train_loader = Data.DataLoader(\n","        dataset=Data.TensorDataset(x, y), \n","        batch_size=1,  \n","        shuffle=True,  \n","        num_workers=2, \n","    )\n","lstm = LSTM()  \n","loss_function = nn.BCELoss()  # loss\n","optimizer = torch.optim.Adam(lstm.parameters(), lr=0.001)  \n","epochs = 10\n","    \n","lstm.train()\n","for i in range(epochs):\n","    for seq, labels in train_loader:\n","        optimizer.zero_grad()\n","        y_pred = lstm(seq).squeeze()  \n","        labels = labels.squeeze()\n","        single_loss = loss_function(y_pred, labels)\n","           \n","        single_loss.backward()\n","        optimizer.step()\n","       \n","lstm.eval()\n","\n","for seq, labels in train_loader:  \n","    y_pred = lstm(seq).squeeze()  \n","    labels = labels.squeeze()\n","    single_loss = loss_function(y_pred, labels)\n","    print(y_pred)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"f4770c04","metadata":{"id":"f4770c04"},"outputs":[],"source":["a = np.ones((60,200,100))\n","b = test[0].values\n","for i in range(60):\n","    a[i]=b[i].reshape(200,100)\n","    \n","x, y = torch.from_numpy(a.astype(float)).to(torch.float32), torch.from_numpy(np.array(train[1].values)).to(torch.float32)\n","y_test_pred = lstm(x).squeeze()  \n","result = []\n","for i in y_test_pred:\n","    if i >0.5:\n","        result.append(1)\n","    else:\n","        result.append(0)\n","\n","acc = sum(result==test[1].values)/60\n","print(acc)"]},{"cell_type":"code","execution_count":null,"id":"4f5f5ba2","metadata":{"id":"4f5f5ba2"},"outputs":[],"source":[""]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"name":"LP2_task.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":5}